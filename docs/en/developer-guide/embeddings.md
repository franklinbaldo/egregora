# Recupera√ß√£o Sem√¢ntica com Gemini Embeddings

O m√≥dulo de RAG (Retrieval-Augmented Generation) do Egr√©gora indexa as
newsletters em um vetor store usando embeddings do Gemini fornecidos pelo
[LlamaIndex](https://www.llamaindex.ai/). Este documento resume o fluxo atual,
os pontos de configura√ß√£o dispon√≠veis e como habilitar a funcionalidade quando
ela for necess√°ria.

---

## üß† Vis√£o Geral do Fluxo

1. `NewsletterRAG` (`src/egregora/rag/index.py`) carrega ou cria um √≠ndice
   vetorial persistente em `cache/vector_store/`.
2. As newsletters (`*.md`) s√£o quebradas em chunks com `TokenTextSplitter` e
   inseridas no √≠ndice.
3. As buscas executam similaridade sem√¢ntica via `VectorIndexRetriever`, com
   filtros para ignorar dias muito recentes conforme configura√ß√£o.
4. Os embeddings s√£o gerados por `CachedGeminiEmbedding`
   (`src/egregora/rag/embeddings.py`), que usa a API oficial do Gemini quando a
   vari√°vel `GOOGLE_API_KEY` est√° presente e recorre a um fallback determin√≠stico
   offline quando n√£o est√°.

---

## ‚öôÔ∏è Configura√ß√£o

A classe `RAGConfig` controla todo o comportamento. Os campos mais relevantes
s√£o:

| Campo                   | Padr√£o                    | Descri√ß√£o |
|-------------------------|---------------------------|-----------|
| `enabled`               | `False`                   | Ativa o uso do RAG no pipeline ou MCP server. |
| `embedding_model`       | `"models/gemini-embedding-001"` | Modelo usado para gerar embeddings. |
| `embedding_dimension`   | `768`                     | Dimens√£o dos vetores retornados. |
| `enable_cache`          | `True`                    | Persiste vetores em `cache/embeddings/`. |
| `export_embeddings`     | `False`                   | Gera um arquivo Parquet com todos os chunks indexados. |
| `embedding_export_path` | `artifacts/embeddings/newsletter_chunks.parquet` | Caminho padr√£o do Parquet exportado (respeita caminhos relativos). |
| `vector_store_type`     | `"simple"`               | Usa `SimpleVectorStore` (in-memory + persist√™ncia local). |
| `chunk_size` / `chunk_overlap` | `1800` / `360`     | Tamanho e overlap dos trechos gerados pelo splitter. |
| `top_k` / `min_similarity`     | `5` / `0.65`        | Ajustes padr√£o para consultas sem√¢nticas. |

Defini√ß√£o completa: `src/egregora/rag/config.py`.

### Via `egregora.toml`

Habilite a se√ß√£o `[rag]` no arquivo de configura√ß√£o:

```toml
[rag]
enabled = true
embedding_model = "models/gemini-embedding-001"
embedding_dimension = 768
# Exporta embeddings em Parquet para publicar em artefatos
export_embeddings = true
embedding_export_path = "artifacts/embeddings/newsletter_chunks.parquet"
```

Qualquer campo omitido usa os defaults acima. Quando `enabled = true`, o m√≥dulo
passa a ser carregado pelo MCP server automaticamente.

### Via Python

```python
from pathlib import Path
from egregora.rag import NewsletterRAG
from egregora.rag.config import RAGConfig

config = RAGConfig(enabled=True, embedding_dimension=768)
rag = NewsletterRAG(
    newsletters_dir=Path("data/newsletters"),
    cache_dir=Path("cache"),
    config=config,
)
rag.update_index(force_rebuild=True)
results = rag.search("automa√ß√µes discutidas", top_k=3)
```

---

## üíæ Cache e Fallback

- Os vetores ficam em `cache/embeddings/` juntamente com metadados do modelo.
- `CachedGeminiEmbedding` grava cada embedding identificado por hash, evitando
  custos repetidos de API.
- Se a API n√£o estiver dispon√≠vel, o fallback interno usa hashing determin√≠stico
  para produzir vetores est√°veis, garantindo que o MCP server continue
  respondendo mesmo offline.

---

## üì¶ Exporta√ß√£o e Artefatos

- Com `export_embeddings = true`, cada execu√ß√£o de `update_index()` escreve um
  Parquet em `embedding_export_path` contendo, por chunk, o texto, metadados e o
  vetor (como coluna de listas). O arquivo √© sobrescrito em toda atualiza√ß√£o.
- O caminho aceita valores relativos; por padr√£o salvamos em
  `artifacts/embeddings/newsletter_chunks.parquet`, facilitando o upload como
  artefato de GitHub Actions.
- Em workflows CI/CD, basta adicionar um passo de upload, por exemplo:

  ```yaml
  - name: Publicar embeddings
    uses: actions/upload-artifact@v4
    with:
      name: newsletter-embeddings
      path: artifacts/embeddings/newsletter_chunks.parquet
  ```

- Para enviar ao Internet Archive, reutilize o mesmo arquivo exportado; apenas
  certifique-se de executar o workflow com a chave apropriada e evite expor
  dados sens√≠veis no Parquet.

---

## üîç Consultas e Integra√ß√£o

- `NewsletterRAG.search(...)` retorna `NodeWithScore`, contendo o texto do chunk,
  a similaridade e metadados (data, se√ß√£o) prontos para formata√ß√£o.
- O MCP server exp√µe as ferramentas `search_newsletters`, `list_newsletters` e
  `get_newsletter`, reutilizando o √≠ndice carregado uma √∫nica vez por execu√ß√£o.
  

---

## ‚úÖ Boas Pr√°ticas

- Execute `update_index(force_rebuild=True)` sempre que uma grande quantidade de
  newsletters for adicionada de uma vez.
- Mantenha a vari√°vel `GOOGLE_API_KEY` configurada para obter embeddings reais;
  sem ela o fallback funciona, mas os resultados s√£o menos precisos.
- Utilize `cache_dir` dedicado em ambientes com m√∫ltiplos usu√°rios para evitar
  conflitos de permiss√µes.

---

## üöÄ Pr√≥ximos Passos Sugeridos

1. Adicionar testes automatizados para `CachedGeminiEmbedding` e o pipeline de
   indexa√ß√£o.
2. Documentar benchmarks comparando o fallback determin√≠stico com embeddings
   reais.
3. Permitir escolha din√¢mica de `vector_store_type` via CLI/TOML quando outras
   op√ß√µes (ex.: Chroma) forem necess√°rias.

Manter esta p√°gina alinhada com o c√≥digo evita confus√£o sobre flags antigas e
refor√ßa que a stack atual gira em torno do Gemini + LlamaIndex, com fallback
confi√°vel para ambientes offline.
