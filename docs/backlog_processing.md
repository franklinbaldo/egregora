# Processamento de Backlog

Este guia descreve como usar os utilitÃ¡rios de backlog para transformar vÃ¡rios dias de conversas do WhatsApp em newsletters diÃ¡rias.

## VisÃ£o Geral

O fluxo de backlog usa o `BacklogProcessor` para:

1. Mapear arquivos `.zip` pendentes.
2. Estimar custos e tempo de processamento.
3. Processar cada dia sequencialmente com checkpoint automÃ¡tico.
4. Retomar execuÃ§Ãµes interrompidas sem perder progresso.

## PrÃ©-requisitos

- Arquivos `.zip` do WhatsApp nomeados com a data (ex.: `2024-10-01.zip`).
- `GEMINI_API_KEY` configurada no ambiente.
- DependÃªncias instaladas (`uv sync`).

## Estrutura de Arquivos

```
project/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ zips/
â”‚       â”œâ”€â”€ 2024-10-01.zip
â”‚       â””â”€â”€ 2024-10-02.zip
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ reports/
â”‚       â””â”€â”€ daily/
â””â”€â”€ cache/
    â””â”€â”€ backlog_checkpoint.json
```

## Script Principal (`scripts/process_backlog.py`)

### Escanear pendÃªncias

```bash
python scripts/process_backlog.py --scan
```

Exemplo de saÃ­da:

```
ğŸ“Š AnÃ¡lise de Backlog
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total de zips encontrados: 12
Newsletters jÃ¡ existentes: 4
Dias pendentes: 8

PerÃ­odo: 2024-08-15 atÃ© 2024-08-26

EstatÃ­sticas estimadas:
- Total de mensagens: ~1.540
- Total de URLs: ~120
- Tempo estimado: ~85.0 min
- Custo estimado: $1.54 USD
```

### Processar dias

```bash
python scripts/process_backlog.py --start-date 2024-08-15 --max-per-run 3
```

OpÃ§Ãµes importantes:

- `--resume`: retoma do Ãºltimo checkpoint.
- `--dry-run`: simula o processamento sem gerar newsletters.
- `--skip-enrichment`: pula enriquecimento de URLs para reduzir custo.
- `--force-rebuild`: reprocessa mesmo se a newsletter existir.
- `--max-per-run N`: limita a quantidade processada em uma Ãºnica execuÃ§Ã£o.

## RelatÃ³rios (`scripts/backlog_report.py`)

Gerar relatÃ³rio resumido:

```bash
python scripts/backlog_report.py
```

Gerar relatÃ³rio detalhado com exportaÃ§Ã£o JSON:

```bash
python scripts/backlog_report.py --detailed --output report.json
```

## Checkpoints

O arquivo `cache/backlog_checkpoint.json` Ã© atualizado automaticamente apÃ³s cada dia. Ele inclui:

- `last_processed_date`: Ãºltimo dia concluÃ­do.
- `total_processed`: total acumulado de dias processados.
- `total_pending`: estimativa de pendÃªncias restantes.
- `failed_dates`: lista de dias com falha.
- `statistics`: mÃ©tricas da Ãºltima execuÃ§Ã£o (mensagens, tempo, custo estimado).

Para reiniciar do zero, exclua o arquivo de checkpoint e execute o script novamente.

## Troubleshooting

- **Erro de API ou rate limit:** o processador aplica backoff exponencial automaticamente. Ajuste `processing.max_retries` e `processing.delay_between_days` em `scripts/backlog_config.yaml`.
- **Arquivos corrompidos:** o scanner ignora `.zip` sem data vÃ¡lida ou com erro de leitura. Verifique o arquivo manualmente.
- **Custos elevados:** use `--skip-enrichment` e processe em lotes menores com `--max-per-run`.

## ConfiguraÃ§Ã£o AvanÃ§ada

Personalize `scripts/backlog_config.yaml` para ajustar delays, timeout, logging e checkpoints. Para usar outro arquivo de configuraÃ§Ã£o, passe `--config caminho/config.yaml` ao chamar o script.

## FAQ

**Posso processar mÃºltiplos dias em paralelo?**
: O pipeline atual Ã© sequencial para simplificar rate limiting. Para grandes volumes, execute em lotes menores.

**Como saber o progresso durante a execuÃ§Ã£o?**
: Monitore os logs em `cache/backlog_processing.log` ou execute `python scripts/backlog_report.py` em outro terminal.

**Posso reprocessar um dia especÃ­fico?**
: Use `--force-rebuild` e filtre o intervalo com `--start-date`/`--end-date`.

---

Pronto! Agora vocÃª pode manter o backlog em dia com seguranÃ§a e previsibilidade.
