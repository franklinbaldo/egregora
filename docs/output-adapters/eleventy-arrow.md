# Eleventy + Arrow Output Adapter

The `EleventyArrowAdapter` writes per-window Parquet files instead of individual markdown files. Eleventy reads these Parquet files at build time to generate static HTML.

## Architecture

```
output/
  data/                         # Generated by Egregora
    window_0.parquet
    window_1.parquet
    window_2.parquet
  eleventy/                     # Eleventy site (copy from template)
    src/_data/documents.js      # Loads all Parquet files
    src/posts/post.njk          # Post template
    .eleventy.js                # Config
```

## Benefits

- **No markdown files**: Posts stored as columnar data, not individual `.md` files
- **Efficient storage**: Parquet compression reduces disk usage
- **Fast builds**: Eleventy loads all data once, no filesystem scanning
- **Query-friendly**: Use DuckDB to query Parquet directly

## Usage

### 1. Use EleventyArrowAdapter in your code

```python
from pathlib import Path
from egregora.output_adapters.eleventy_arrow_adapter import EleventyArrowAdapter

# Create adapter
adapter = EleventyArrowAdapter(
    site_root=Path("output"),
    url_context=None  # Not used by this adapter
)

# Serve documents (pipeline sets source_window automatically)
adapter.serve(document1)
adapter.serve(document2)

# Finalize window (writes Parquet)
adapter.finalize_window("2025-01-11 10:00 to 12:00", [], [], {"window_index": 0})
```

### 2. Set up Eleventy site

```bash
# Copy template to output directory
cp -r src/egregora/output_adapters/eleventy_template output/eleventy

# Install dependencies
cd output/eleventy
npm install
```

### 3. Generate content

Run your Egregora pipeline with `EleventyArrowAdapter`. The adapter will create Parquet files in `output/data/`.

### 4. Build Eleventy site

```bash
cd output/eleventy
npm run build  # Builds to _site/
npm run serve  # Dev server at http://localhost:8080
```

## How It Works

### Egregora Side (Python)

The adapter buffers documents in memory per-window and writes Parquet when `finalize_window()` is called:

```python
# Called by writer agent for each document
def serve(self, document: Document) -> None:
    window_label = document.source_window  # e.g., "2025-01-11 10:00 to 12:00"
    self._buffers[window_label].append(document)

# Called by pipeline after window completes
def finalize_window(self, window_label, ..., metadata):
    window_index = metadata.get("window_index", 0)
    table = self._documents_to_arrow(self._buffers[window_label])
    pq.write_table(table, f"data/window_{window_index}.parquet")
```

### Eleventy Side (JavaScript)

The data loader reads all Parquet files and exposes them as `{{ documents }}`:

```javascript
// src/_data/documents.js
const parquet = require("parquetjs");

module.exports = async function () {
  const files = fs
    .readdirSync("../../data")
    .filter((f) => f.endsWith(".parquet"))
    .sort();

  const documents = [];
  for (const file of files) {
    const reader = await parquet.ParquetReader.openFile(`../../data/${file}`);
    const cursor = reader.getCursor();

    let record = null;
    while ((record = await cursor.next())) {
      documents.push({
        id: record.id,
        slug: record.slug,
        kind: record.kind,
        title: record.title,
        body_md: record.body_md,
        created_at: record.created_at,
        metadata: JSON.parse(record.metadata),
      });
    }
    await reader.close();
  }

  return documents;
};
```

Templates use collections:

```njk
{# src/posts/post.njk #}
---
pagination:
  data: collections.posts
  size: 1
  alias: post
permalink: "/posts/{{ post.slug }}/"
---

<h1>{{ post.title }}</h1>
{{ post.body_md | markdown | safe }}
```

## Parquet Schema

Each Parquet file has the following schema:

| Column | Type | Description |
|--------|------|-------------|
| `id` | string | Document UUID (content-addressed) |
| `slug` | string | URL slug (e.g., "my-post") |
| `kind` | string | Document type: post, profile, journal, enrichment_url, enrichment_media, media |
| `title` | string | Document title |
| `body_md` | string | Markdown content |
| `created_at` | string | ISO 8601 timestamp |
| `metadata` | string | JSON-encoded metadata dict |
| `parent_id` | string | Parent document ID (for enrichments) |

## Querying with DuckDB

You can query Parquet files directly without Eleventy:

```bash
duckdb
```

```sql
-- Count documents by type
SELECT kind, COUNT(*) as count
FROM read_parquet('output/data/window_*.parquet')
GROUP BY kind;

-- Recent posts
SELECT title, created_at
FROM read_parquet('output/data/window_*.parquet')
WHERE kind = 'post'
ORDER BY created_at DESC
LIMIT 10;

-- Search content
SELECT title, slug
FROM read_parquet('output/data/window_*.parquet')
WHERE body_md LIKE '%keyword%'
  AND kind = 'post';
```

## Deployment

Deploy the built `_site/` directory to any static host:

```bash
cd output/eleventy
npm run build

# Netlify
netlify deploy --dir=_site --prod

# Vercel
vercel --prod _site

# GitHub Pages
git add _site -f
git subtree push --prefix output/eleventy/_site origin gh-pages
```

## Comparison with MkDocs

| Feature | MkDocs (default) | Eleventy + Arrow |
|---------|------------------|------------------|
| Output files | 100s of `.md` | 1-10 `.parquet` |
| Storage format | Filesystem | Columnar (Parquet) |
| Build tool | Python (MkDocs) | JavaScript (Eleventy) |
| Queryable | No | Yes (DuckDB) |
| Theme flexibility | MkDocs themes | Full HTML/CSS/JS control |
| Incremental builds | Yes (file mtime) | No (full rebuild) |

## Customization

### Styling

Edit `src/_includes/base.njk` or add CSS:

```bash
mkdir -p src/assets
cat > src/assets/style.css <<EOF
body { font-family: Georgia, serif; }
h1 { color: #2c3e50; }
EOF
```

### New Templates

Create templates for other document types:

```njk
{# src/profiles/profile.njk #}
---
pagination:
  data: collections.profiles
  size: 1
  alias: profile
permalink: "/profiles/{{ profile.metadata.uuid }}/"
---

<h1>{{ profile.metadata.name }}</h1>
<div>{{ profile.body_md | markdown | safe }}</div>
```

### Custom Collections

Define collections in `.eleventy.js`:

```javascript
eleventyConfig.addCollection("tagged_ai", (collectionApi) => {
  const docs = collectionApi.globalData.documents || [];
  return docs.filter((d) =>
    d.kind === "post" &&
    d.metadata.tags &&
    d.metadata.tags.includes("ai")
  );
});
```

## Troubleshooting

**Error: "Document must have source_window set"**
- The writer agent should set `source_window` automatically
- If calling `serve()` manually, ensure `document.source_window` is set

**No Parquet files generated**
- Check that `finalize_window()` is called after window processing
- Verify `site_root/data/` directory exists and is writable

**Eleventy build fails: "Cannot find module 'parquetjs'"**
- Run `npm install` in the `output/eleventy` directory

**Empty documents array in Eleventy**
- Check that Parquet files exist in `output/data/`
- Verify `src/_data/documents.js` has correct relative path `../../data`
