"""Enhanced command line interface for Egregora with subcommands."""

from __future__ import annotations

import json
import logging
import warnings
from datetime import date, datetime
from pathlib import Path
from zoneinfo import ZoneInfo


# Suppress the specific Pydantic warning about `validate_default`
# This must be done before importing other modules that might trigger the warning
from pydantic.warnings import UnsupportedFieldAttributeWarning
warnings.filterwarnings("ignore", category=UnsupportedFieldAttributeWarning, message=".*`validate_default`.*")


import typer
from rich.console import Console
from rich.logging import RichHandler
from rich.panel import Panel
from rich.table import Table

from .config import (
    AnonymizationConfig,
    CacheConfig,
    EnrichmentConfig,
    LLMConfig,
    PipelineConfig,
    ProfilesConfig,
    DEFAULT_MODEL,
)
from .processor import UnifiedProcessor
from .rag.config import RAGConfig

MAX_POSTS_TO_SHOW = 3
MAX_DATES_TO_SHOW = 10
QUOTA_WARNING_THRESHOLD = 200
QUOTA_WARNING_THRESHOLD_ENRICH = 15

console = Console()


# Configure logging to use Rich for pretty output
logging.basicConfig(
    level=logging.INFO,
    format="%(message)s",
    datefmt="[%X]",
    handlers=[RichHandler(console=console, show_path=False, show_level=False, show_time=False, rich_tracebacks=True)],
)


app = typer.Typer(help="Egregora - WhatsApp to post pipeline with AI enrichment")


@app.command("process")
def process_command(  # noqa: PLR0913
    zip_files: list[Path] = typer.Argument(
        ..., help="Um ou mais arquivos .zip do WhatsApp para processar"
    ),
    output_dir: Path | None = typer.Option(
        None, "--output", "-o", help="Diret√≥rio onde as posts ser√£o escritas"
    ),
    group_name: str | None = typer.Option(
        None,
        "--group-name",
        help="Nome do grupo (auto-detectado se n√£o fornecido)",
    ),
    group_slug: str | None = typer.Option(
        None,
        "--group-slug",
        help="Slug do grupo (auto-gerado se n√£o fornecido)",
    ),
    model: str = typer.Option(
        DEFAULT_MODEL,
        "--model",
        help="Nome do modelo Gemini a ser usado",
    ),
    timezone: str = typer.Option(
        "America/Porto_Velho", "--timezone", help="Timezone IANA"
    ),
    days: int | None = typer.Option(
        None,
        "--days",
        min=1,
        help="Processar os N dias mais recentes. Incompat√≠vel com --from/--to.",
    ),
    from_date: str | None = typer.Option(
        None,
        "--from-date",
        help="Data de in√≠cio (YYYY-MM-DD). Incompat√≠vel com --days.",
        formats=["%Y-%m-%d"],
    ),
    to_date: str | None = typer.Option(
        None,
        "--to-date",
        help="Data de fim (YYYY-MM-DD). Incompat√≠vel com --days.",
        formats=["%Y-%m-%d"],
    ),
    disable_enrichment: bool = typer.Option(
        False,
        "--disable-enrichment",
        "--no-enrich",
        help="Desativa o enriquecimento",
    ),
    disable_cache: bool = typer.Option(
        False, "--no-cache", help="Desativa o cache persistente"
    ),
    list_groups: bool = typer.Option(
        False, "--list", "-l", help="Lista grupos descobertos e sai"
    ),
    dry_run: bool = typer.Option(
        False,
        "--dry-run",
        help="Simula a execu√ß√£o e mostra quais posts seriam geradas",
    ),
    link_member_profiles: bool = typer.Option(
        True,
        "--link-profiles/--no-link-profiles",
        help="Link member mentions to profile pages",
    ),
    profile_base_url: str = typer.Option(
        "/profiles/", "--profile-base-url", help="Base URL for profile links"
    ),
    safety_threshold: str = typer.Option(
        "BLOCK_NONE", "--safety-threshold", help="Gemini safety threshold"
    ),
    thinking_budget: int = typer.Option(
        -1, "--thinking-budget", help="Gemini thinking budget (-1 for unlimited)"
    ),
    max_links: int = typer.Option(
        50, "--max-links", help="Maximum links to enrich per post"
    ),
    relevance_threshold: int = typer.Option(
        2,
        "--relevance-threshold",
        help="Minimum relevance threshold for enrichment",
    ),
    cache_dir: Path = typer.Option(
        Path("cache"), "--cache-dir", help="Cache directory path"
    ),
    auto_cleanup_days: int = typer.Option(
        90, "--auto-cleanup-days", help="Auto cleanup cache after N days"
    ),
) -> None:
    """Processa um ou mais arquivos .zip do WhatsApp e gera posts di√°rias."""

    # Configuration now uses only CLI arguments

    # Mutual exclusivity validation

    if days is not None and (from_date is not None or to_date is not None):
        console.print("‚ùå A op√ß√£o --days n√£o pode ser usada com --from-date ou --to-date.")
        raise typer.Exit(1)

    # Date parsing and validation
    from_date_obj = None
    to_date_obj = None

    if from_date:
        try:
            from_date_obj = datetime.strptime(from_date, "%Y-%m-%d").date()
        except ValueError as e:
            console.print(f"‚ùå Data de in√≠cio inv√°lida: '{from_date}'. Use YYYY-MM-DD.")
            raise typer.Exit(1) from e

    if to_date:
        try:
            to_date_obj = datetime.strptime(to_date, "%Y-%m-%d").date()
        except ValueError as e:
            console.print(f"‚ùå Data de fim inv√°lida: '{to_date}'. Use YYYY-MM-DD.")
            raise typer.Exit(1) from e

    # Date range validation
    if from_date_obj and to_date_obj and from_date_obj > to_date_obj:
        console.print("‚ùå Data de in√≠cio deve ser anterior √† data de fim.")
        raise typer.Exit(1)

    # Convert days to days_to_process for backward compatibility
    days_to_process = days

    # Normalize input paths
    zip_files = [path.resolve() for path in zip_files]

    # Build nested configuration objects
    llm_config = LLMConfig(safety_threshold=safety_threshold, thinking_budget=thinking_budget)

    enrichment_config = EnrichmentConfig(
        enabled=not disable_enrichment, max_links=max_links, relevance_threshold=relevance_threshold
    )

    cache_config = CacheConfig(
        enabled=not disable_cache, cache_dir=cache_dir, auto_cleanup_days=auto_cleanup_days
    )

    profiles_config = ProfilesConfig(
        link_members_in_posts=link_member_profiles, profile_base_url=profile_base_url
    )

    # Build main configuration
    posts_dir = (output_dir if output_dir else Path("data")).resolve()

    config = PipelineConfig(
        zip_files=zip_files,
        posts_dir=posts_dir,
        group_name=group_name,
        group_slug=group_slug,
        model=model,
        timezone=ZoneInfo(timezone),
        llm=llm_config,
        enrichment=enrichment_config,
        cache=cache_config,
        profiles=profiles_config,
        anonymization=AnonymizationConfig(),
        rag=RAGConfig(),
    )

    # Configuration is now fully built from CLI arguments above

    # Create processor instance
    processor = UnifiedProcessor(config)

    # List groups and exit if requested
    if list_groups:
        _list_groups_and_exit(processor)

    # Dry run mode
    if dry_run:
        _dry_run_and_exit(processor, days_to_process, from_date_obj, to_date_obj)

    # Process normally
    _process_and_display(
        processor,
        days=days_to_process,
        from_date=from_date_obj,
        to_date=to_date_obj,
    )


@app.command("profiles")
def profiles_command(
    action: str = typer.Argument(..., help="A√ß√£o: list, show, generate, clean"),
    target: str | None = typer.Argument(None, help="ID do membro ou caminho do ZIP (para generate)"),
    output_format: str = typer.Option("pretty", "--format", "-f", help="Formato: pretty, json"),
) -> None:
    """Gerencia perfis de participantes."""

    if action not in ["list", "show", "generate", "clean"]:
        console.print(f"‚ùå A√ß√£o inv√°lida: {action}. Use: list, show, generate, clean")
        raise typer.Exit(1)

    # Build config using CLI arguments
    config = PipelineConfig(
        zip_files=[],
        llm=LLMConfig(),
        enrichment=EnrichmentConfig(),
        cache=CacheConfig(),
        profiles=ProfilesConfig(),
        anonymization=AnonymizationConfig(),
        rag=RAGConfig(),
    )

    if action == "list":
        _list_profiles(config, output_format)
    elif action == "show":
        if not target:
            console.print("‚ùå Especifique o ID do membro para mostrar")
            raise typer.Exit(1)
        _show_profile(config, target, output_format)
    elif action == "generate":
        if not target:
            console.print("‚ùå Especifique o caminho do ZIP para gerar perfis")
            raise typer.Exit(1)
        _generate_profiles(config, Path(target))
    elif action == "clean":
        _clean_profiles(config)


def _list_profiles(config: PipelineConfig, output_format: str) -> None:
    """Lista perfis existentes."""
    profiles_dir = config.posts_dir / "profiles" / "json"

    if not profiles_dir.exists():
        console.print("üìÅ Nenhum diret√≥rio de perfis encontrado")
        return

    profile_files = list(profiles_dir.glob("*.json"))

    if not profile_files:
        console.print("üë§ Nenhum perfil encontrado")
        return

    if output_format == "json":
        profiles_data = []
        for profile_file in profile_files:
            try:
                with open(profile_file) as f:
                    profile_data = json.load(f)
                    profiles_data.append(
                        {
                            "member_id": profile_file.stem,
                            "name": profile_data.get("name", "Unknown"),
                            "message_count": profile_data.get("message_count", 0),
                            "last_updated": profile_data.get("last_updated", "Unknown"),
                        }
                    )
            except Exception:
                continue
        console.print(json.dumps(profiles_data, indent=2, ensure_ascii=False))
    else:
        table = Table(title="üë• Perfis de Participantes")
        table.add_column("ID do Membro", style="cyan")
        table.add_column("Nome", style="green")
        table.add_column("Mensagens", style="yellow")
        table.add_column("√öltima Atualiza√ß√£o", style="blue")

        for profile_file in profile_files:
            try:
                with open(profile_file) as f:
                    profile_data = json.load(f)
                    table.add_row(
                        profile_file.stem,
                        profile_data.get("name", "Unknown"),
                        str(profile_data.get("message_count", 0)),
                        profile_data.get("last_updated", "Unknown"),
                    )
            except Exception:
                table.add_row(profile_file.stem, "‚ùå Erro ao ler", "-", "-")

        console.print(table)


def _show_profile(config: PipelineConfig, member_id: str, output_format: str) -> None:
    """Mostra detalhes de um perfil espec√≠fico."""
    profiles_dir = config.posts_dir / "profiles" / "json"
    profile_file = profiles_dir / f"{member_id}.json"

    if not profile_file.exists():
        console.print(f"‚ùå Perfil n√£o encontrado: {member_id}")
        raise typer.Exit(1)

    try:
        with open(profile_file) as f:
            profile_data = json.load(f)

        if output_format == "json":
            console.print(json.dumps(profile_data, indent=2, ensure_ascii=False))
        else:
            console.print(
                Panel(
                    f"[bold]Nome:[/bold] {profile_data.get('name', 'Unknown')}\n"
                    f"[bold]ID do Membro:[/bold] {member_id}\n"
                    f"[bold]Mensagens:[/bold] {profile_data.get('message_count', 0)}\n"
                    f"[bold]Primeira Atividade:[/bold] {profile_data.get('first_seen', 'Unknown')}\n"
                    f"[bold]√öltima Atividade:[/bold] {profile_data.get('last_seen', 'Unknown')}\n"
                    f"[bold]√öltima Atualiza√ß√£o:[/bold] {profile_data.get('last_updated', 'Unknown')}\n\n"
                    f"[bold]Descri√ß√£o:[/bold]\n{profile_data.get('description', 'Nenhuma descri√ß√£o dispon√≠vel')}\n\n"
                    f"[bold]T√≥picos Principais:[/bold] {', '.join(profile_data.get('main_topics', []))}\n"
                    f"[bold]Estilo de Comunica√ß√£o:[/bold] {profile_data.get('communication_style', 'Unknown')}",
                    title=f"üë§ Perfil: {profile_data.get('name', member_id)}",
                    border_style="blue",
                )
            )
    except Exception as e:
        console.print(f"‚ùå Erro ao ler perfil: {e}")
        raise typer.Exit(1) from e


def _generate_profiles(config: PipelineConfig, zip_path: Path) -> None:
    """Gera perfis a partir de um ZIP do WhatsApp."""
    if not zip_path.exists():
        console.print(f"‚ùå Arquivo ZIP n√£o encontrado: {zip_path}")
        raise typer.Exit(1)

    console.print(f"üë• Gerando perfis a partir de: {zip_path}")

    try:
        # Create processor with the ZIP file
        # Generate profiles (this would need implementation in processor)
        console.print("üîÑ Processando mensagens para gera√ß√£o de perfis...")

        # For now, show what would be done
        console.print("‚úÖ Perfis seriam gerados (funcionalidade em desenvolvimento)")
        console.print("üí° Use 'egregora process' com dados reais para gerar perfis automaticamente")

    except Exception as e:
        console.print(f"‚ùå Erro durante gera√ß√£o de perfis: {e}")
        raise typer.Exit(1) from e


def _clean_profiles(config: PipelineConfig) -> None:
    """Remove perfis antigos ou inv√°lidos."""
    profiles_dir = config.posts_dir / "profiles" / "json"

    if not profiles_dir.exists():
        console.print("üìÅ Nenhum diret√≥rio de perfis encontrado")
        return

    profile_files = list(profiles_dir.glob("*.json"))
    removed_count = 0

    for profile_file in profile_files:
        try:
            with open(profile_file) as f:
                json.load(f)  # Validate JSON
        except Exception:
            profile_file.unlink()
            removed_count += 1
            console.print(f"üóëÔ∏è  Removido perfil corrompido: {profile_file.name}")

    if removed_count == 0:
        console.print("‚úÖ Todos os perfis est√£o v√°lidos")
    else:
        console.print(f"‚úÖ Removidos {removed_count} perfis corrompidos")


# Original helper functions (preserved from the original main function)
def _list_groups_and_exit(processor: UnifiedProcessor) -> None:
    """Lista grupos descobertos e sai."""
    sources_to_process, real_groups, virtual_groups = processor._collect_sources()

    console.print(Panel("[bold green]üìã Grupos Descobertos[/bold green]"))

    if real_groups:
        console.print("\n[bold yellow]üì± Grupos Reais (do WhatsApp):[/bold yellow]")
        for slug, source in real_groups.items():
            date_range = f"{source.earliest_date} ‚Üí {source.latest_date}"
            console.print(f"  ‚Ä¢ {source.name} ({slug}): {date_range}")

    if virtual_groups:
        console.print("\n[bold cyan]üîó Grupos Virtuais (mesclados):[/bold cyan]")
        for slug, config in virtual_groups.items():
            console.print(f"  ‚Ä¢ {config.name} ({slug}): mescla {len(config.source_groups)} grupos")

    console.print(f"\n[dim]Total: {len(sources_to_process)} grupo(s) para processar[/dim]")
    raise typer.Exit()


def _dry_run_and_exit(
    processor: UnifiedProcessor,
    days: int | None,
    from_date: date | None,
    to_date: date | None,
) -> None:
    """Executa dry run e sai."""
    console.print(
        Panel(
            "[bold blue]üîç Modo DRY RUN[/bold blue]\nMostrando o que seria processado sem executar",
            border_style="blue",
        )
    )

    plans = processor.plan_runs(days=days, from_date=from_date, to_date=to_date)
    if not plans:
        console.print("[yellow]Nenhum grupo foi encontrado com os filtros atuais.[/yellow]")
        console.print("Ajuste EGREGORA__POSTS_DIR ou coloque exports em data/whatsapp_zips/.\n")
        return

    total_posts = 0
    for plan in plans:
        icon = "üì∫" if plan.is_virtual else "üìù"
        console.print(f"\n[cyan]{icon} {plan.name}[/cyan] ([dim]{plan.slug}[/dim])")
        console.print(f"   Exports dispon√≠veis: {plan.export_count}")

        if plan.is_virtual and plan.merges:
            console.print(f"   Grupos combinados: {', '.join(plan.merges)}")

        if plan.available_dates:
            console.print(
                f"   Intervalo dispon√≠vel: {plan.available_dates[0]} ‚Üí {plan.available_dates[-1]}"
            )
        else:
            console.print("   Nenhuma data dispon√≠vel nos exports")

        if plan.target_dates:
            if len(plan.target_dates) <= MAX_DATES_TO_SHOW:
                formatted_dates = ", ".join(str(d) for d in plan.target_dates)
            else:
                first_5 = ", ".join(str(d) for d in plan.target_dates[:5])
                last_5 = ", ".join(str(d) for d in plan.target_dates[-5:])
                formatted_dates = f"{first_5}, ..., {last_5}"
            console.print(f"   Ser√° gerado para {len(plan.target_dates)} dia(s): {formatted_dates}")
            total_posts += len(plan.target_dates)
        else:
            console.print("   Nenhuma post seria gerada (sem dados recentes)")

    console.print(f"\nResumo: {len(plans)} grupo(s) gerariam at√© {total_posts} post(s).")

    # Show quota estimation
    try:
        quota_info = processor.estimate_api_usage(days=days, from_date=from_date, to_date=to_date)
        console.print("\nüìä Estimativa de Uso da API:")
        console.print(f"   Chamadas para posts: {quota_info['post_calls']}")
        console.print(f"   Chamadas para enriquecimento: {quota_info['enrichment_calls']}")
        console.print(f"   Total de chamadas: {quota_info['total_api_calls']}")
        console.print(
            f"   Tempo estimado (tier gratuito): {quota_info['estimated_time_minutes']:.1f} minutos"
        )

        if quota_info["total_api_calls"] > QUOTA_WARNING_THRESHOLD:
            console.print(
                "\n[yellow]‚ö†Ô∏è Esta opera√ß√£o pode exceder a quota gratuita do Gemini[/yellow]"
            )
            console.print(
                "[dim]Tier gratuito: 15 chamadas/minuto. Considere processar em lotes menores.[/dim]"
            )

    except Exception as exc:
        console.print(f"\n[yellow]N√£o foi poss√≠vel estimar uso da API: {exc}[/yellow]")

    console.print()
    raise typer.Exit()


def _process_and_display(
    processor: UnifiedProcessor,
    *,
    days: int | None,
    from_date: date | None,
    to_date: date | None,
) -> None:
    """Processa grupos e mostra resultado formatado."""

    # Show quota estimation before processing
    try:
        quota_info = processor.estimate_api_usage(days=days, from_date=from_date, to_date=to_date)
        if quota_info["total_api_calls"] > QUOTA_WARNING_THRESHOLD_ENRICH:
            console.print(
                Panel(
                    f"[yellow]‚ö†Ô∏è Esta opera√ß√£o far√° {quota_info['total_api_calls']} chamadas √† API[/yellow]\n"
                    f"Tempo estimado (tier gratuito): {quota_info['estimated_time_minutes']:.1f} minutos\n"
                    f"[dim]O processamento pode ser interrompido por limites de quota.[/dim]",
                    border_style="yellow",
                    title="Estimativa de Quota",
                )
            )

    except Exception as exc:
        console.print(f"\n[yellow]N√£o foi poss√≠vel estimar uso da API: {exc}[/yellow]")

    console.print()

    console.print(Panel("[bold green]üöÄ Processando Grupos[/bold green]"))

    results = processor.process_all(days=days, from_date=from_date, to_date=to_date)

    total = sum(len(v) for v in results.values())
    table = Table(
        title=f"üìä Resultado do Processamento ({total} posts geradas)",
        show_header=True,
        header_style="bold magenta",
    )
    table.add_column("Grupo", style="cyan", no_wrap=True)
    table.add_column("Posts Geradas", justify="center", style="green")
    table.add_column("Arquivos", style="dim")

    for group_slug, post_paths in results.items():
        files = ", ".join(p.name for p in post_paths[:MAX_POSTS_TO_SHOW])
        if len(post_paths) > MAX_POSTS_TO_SHOW:
            files += f", +{len(post_paths) - MAX_POSTS_TO_SHOW} mais"
        table.add_row(group_slug, str(len(post_paths)), files)

    console.print(table)


def run() -> None:
    """Entry point used by the console script."""
    app()


# Maintain backward compatibility - if called without subcommand, default to process
def main(*args, **kwargs):
    """Backward compatibility wrapper."""
    return process_command(*args, **kwargs)


if __name__ == "__main__":
    run()
