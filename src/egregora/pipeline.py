"""Core newsletter generation pipeline."""

from __future__ import annotations

import os
import re
import zipfile
from dataclasses import dataclass
from datetime import date, datetime, timedelta, tzinfo
from pathlib import Path
from typing import List, Sequence

try:  # pragma: no cover - executed only when dependency is missing
    from google import genai  # type: ignore
    from google.genai import types  # type: ignore
except ModuleNotFoundError:  # pragma: no cover - allows importing without dependency
    genai = None  # type: ignore[assignment]
    types = None  # type: ignore[assignment]

from .config import PipelineConfig

DATE_IN_NAME_RE = re.compile(r"(\d{4}-\d{2}-\d{2})")


def _require_google_dependency() -> None:
    """Ensure the optional google-genai dependency is available."""

    if genai is None or types is None:
        raise RuntimeError(
            "A depend√™ncia opcional 'google-genai' n√£o est√° instalada. "
            "Instale-a para gerar newsletters (ex.: `pip install google-genai`)."
        )


@dataclass(slots=True)
class PipelineResult:
    """Information about an executed pipeline run."""

    output_path: Path
    processed_dates: List[date]
    previous_newsletter_path: Path
    previous_newsletter_found: bool


def find_date_in_name(path: Path) -> date | None:
    """Return the first YYYY-MM-DD date embedded in a filename."""

    match = DATE_IN_NAME_RE.search(path.name)
    if not match:
        return None

    try:
        return datetime.strptime(match.group(1), "%Y-%m-%d").date()
    except ValueError:
        return None


def list_zip_days(zips_dir: Path) -> list[tuple[date, Path]]:
    """Return available zip archives sorted by date."""

    zips: list[tuple[date, Path]] = []
    for path in zips_dir.glob("*.zip"):
        found_date = find_date_in_name(path)
        if found_date is not None:
            zips.append((found_date, path))
    zips.sort(key=lambda item: item[0])
    return zips


def read_zip_texts(zippath: Path) -> str:
    """Read all text files stored inside *zippath* in alphabetical order."""

    chunks: list[str] = []
    with zipfile.ZipFile(zippath, "r") as zipped:
        txt_names = sorted(name for name in zipped.namelist() if name.lower().endswith(".txt"))
        for name in txt_names:
            with zipped.open(name, "r") as file_handle:
                raw = file_handle.read()
            try:
                text = raw.decode("utf-8")
            except UnicodeDecodeError:
                text = raw.decode("latin-1")
            text = text.replace("\r\n", "\n")
            chunks.append(f"\n# Arquivo: {name}\n{text.strip()}\n")
    return "\n".join(chunks).strip()


def load_previous_newsletter(news_dir: Path, reference_date: date) -> tuple[Path, str | None]:
    """Load yesterday's newsletter if it exists."""

    yesterday = reference_date - timedelta(days=1)
    path = news_dir / f"{yesterday.isoformat()}.md"
    if path.exists():
        return path, path.read_text(encoding="utf-8")
    return path, None


def _format_transcript_section_header(transcript_count: int) -> str:
    """Return a localized header describing how many transcripts are included."""

    if transcript_count <= 1:
        return "TRANSCRITO BRUTO DO √öLTIMO DIA (NA ORDEM CRONOL√ìGICA POR DIA):"
    return (
        f"TRANSCRITO BRUTO DOS √öLTIMOS {transcript_count} DIAS "
        "(NA ORDEM CRONOL√ìGICA POR DIA):"
    )


def build_llm_input(
    *,
    group_name: str,
    timezone: tzinfo,
    transcripts: Sequence[tuple[date, str]],
    previous_newsletter: str | None,
    transcript_count: int | None = None,
) -> str:
    """Compose the user prompt sent to Gemini.

    Parameters
    ----------
    transcript_count:
        Optional override for how many days of transcripts are mentioned in the
        header. Defaults to the number of transcript entries provided.
    """

    today_str = datetime.now(timezone).date().isoformat()
    sections: list[str] = [
        f"NOME DO GRUPO: {group_name}",
        f"DATA DE HOJE: {today_str}",
    ]

    if previous_newsletter:
        sections.extend(
            [
                "NEWSLETTER DO DIA ANTERIOR (INCLUA COMO CONTEXTO, N√ÉO COPIE):",
                "<<<NEWSLETTER_ONTEM_INICIO>>>",
                previous_newsletter.strip(),
                "<<<NEWSLETTER_ONTEM_FIM>>>",
            ]
        )
    else:
        sections.append("NEWSLETTER DO DIA ANTERIOR: N√ÉO ENCONTRADA")

    header = _format_transcript_section_header(transcript_count or len(transcripts))
    sections.append(header)
    for transcript_date, transcript_text in transcripts:
        sections.extend(
            [
                f"<<<TRANSCRITO_{transcript_date.isoformat()}_INICIO>>>",
                transcript_text.strip() if transcript_text.strip() else "(vazio)",
                f"<<<TRANSCRITO_{transcript_date.isoformat()}_FIM>>>",
            ]
        )

    return "\n\n".join(sections)


def build_system_instruction() -> list[types.Part]:
    """Return the validated system prompt."""

    _require_google_dependency()

    system_text = r"""
Tarefa: produzir uma newsletter di√°ria a partir de um TRANSCRITO BRUTO de conversas de grupo.

Instru√ß√µes de entrada:
- Voc√™ receber√° um bloco de texto com mensagens no formato "HH:MM ‚Äî Remetente: Mensagem" (podem existir variantes).
- O remetente pode vir como nick, n√∫mero de telefone ou ambos. Links podem aparecer soltos na mensagem.

Objetivo:
- Redigir um relat√≥rio di√°rio em portugu√™s, em estilo de "newsletter", organizado em FIOS (threads), narrado como se o GRUPO fosse UMA √öNICA MENTE COLETIVA ("n√≥s").
- A newsletter deve SER a voz do grupo, n√£o uma an√°lise SOBRE o grupo.
- Em CADA FRASE do corpo narrativo, colocar o autor entre par√™nteses imediatamente ap√≥s a frase. Se houver nick, usar (Nick). Se n√£o houver nick, usar os quatro d√≠gitos finais do telefone, no formato (1234).
- Inserir CADA LINK COMPARTILHADO no ponto exato em que ele √© mencionado (link completo, clic√°vel). N√£o agrupar links no final.
- EXPLICITAR subentendidos, tens√µes, mudan√ßas de posi√ß√£o e contextos. N√£o deixar impl√≠cito o que est√° acontecendo em cada momento.
- N√£o inventar nicks. N√£o resumir links. N√£o ocultar mensagens relevantes.

Regras de formata√ß√£o do relat√≥rio:
1) Cabe√ßalho:
   - T√≠tulo: "üì© {NOME DO GRUPO} ‚Äî Di√°rio de {DATA}"
   - Uma linha introdut√≥ria, no plural ("n√≥s"), explicando que o dia foi organizado em fios.

2) Estrutura por FIOS (n√£o "arcos", n√£o "se√ß√µes"):
   - Separar o dia em 4‚Äì10 FIOS, cada um com t√≠tulo descritivo e expl√≠cito no formato:
     "## Fio X ‚Äî {t√≠tulo que contextualize claramente o momento/debate/tema}"
   - Cada FIO deve come√ßar com 1-2 frases de CONTEXTO explicando o que est√° acontecendo naquele momento da nossa mente coletiva, POR QUE aquele tema surgiu, COMO ele se conecta (ou n√£o) ao anterior.
   - Crit√©rios para separar FIOS:
     ‚Ä¢ Mudan√ßa clara de tema OU
     ‚Ä¢ Intervalos de tempo significativos OU
     ‚Ä¢ Troca dominante de participantes OU
     ‚Ä¢ Mudan√ßa de tom/intensidade.
   - Dentro de cada FIO, escrever em 1¬™ pessoa do plural ("n√≥s"), como a mente do grupo, e:
     ‚Ä¢ CONTEXTUALIZAR: explicar o que est√° acontecendo, n√£o apenas reportar.
     ‚Ä¢ EXPLICITAR: tese, ant√≠tese, consensos, diverg√™ncias, tens√µes n√£o resolvidas.
     ‚Ä¢ SUBENTENDIDOS: transformar impl√≠citos em expl√≠citos ("Declaramos que‚Ä¶", "Contestamos porque‚Ä¶", "Uma parte de n√≥s temia que‚Ä¶").
     ‚Ä¢ Citar os links no exato ponto onde foram trazidos, mantendo o link completo.
     ‚Ä¢ Em CADA FRASE do corpo narrativo, ao final, inserir (Nick) ou (quatro d√≠gitos).

3) Regras de autoria (entre par√™nteses):
   - Se a linha do remetente tiver nick ‚Üí usar exatamente esse nick entre par√™nteses.
   - Se N√ÉO houver nick, extrair os quatro d√≠gitos finais do n√∫mero: ex.: +55 11 94529-4774 ‚Üí (4774).
   - Se houver m√≠dia sem descri√ß√£o ("<M√≠dia oculta>"), registrar explicitamente "enviamos m√≠dia sem descri√ß√£o" (autor entre par√™nteses).
   - Se a mensagem estiver marcada como editada, pode acrescentar "(editado)" antes do autor.
   - IMPORTANTE: o autor aparece em CADA FRASE de conte√∫do substantivo, n√£o apenas uma vez por par√°grafo.

4) Tratamento de links:
   - Sempre inserir o link COMPLETO no ponto exato da narrativa em que ele foi mencionado originalmente.
   - N√£o encurtar, n√£o mover para rodap√©, n√£o omitir.
   - Pode haver uma frase curta de contexto sobre o link SE o contexto n√£o for √≥bvio.

5) Estilo e clareza:
   - Voz: 1¬™ pessoa do plural ("n√≥s"), IMEDIATA, como se o grupo estivesse narrando a si mesmo.
   - N√£o usar metalinguagem de planejamento ("vamos estruturar", "o arco se divide", "conectivos"). A newsletter √â a narrativa, n√£o uma an√°lise sobre a narrativa.
   - Explicativo e contextual: diga o que cada parte de n√≥s defende e POR QU√ä; diga POR QU√ä as alternativas foram refutadas; diga QUANDO mudamos de assunto e POR QU√ä.
   - Zero mist√©rio: torne expl√≠citos pressupostos, implica√ß√µes, trade-offs, tens√µes n√£o resolvidas.
   - Evitar jarg√£o n√£o explicado; quando usar, explique brevemente inline.
   - Tom natural, n√£o excessivamente formal, mas tamb√©m n√£o casual demais.

6) Ep√≠logo:
   - Fechar com um par√°grafo "Ep√≠logo" resumindo:
     ‚Ä¢ Principais consensos e dissensos do dia.
     ‚Ä¢ O que ficou em aberto ou n√£o resolvido.
     ‚Ä¢ Pr√≥ximos passos impl√≠citos (se existirem) ‚Äî explicitados.
     ‚Ä¢ Tens√µes que permaneceram sem resolu√ß√£o.

7) Qualidade (checklist antes de finalizar):
   - [ ] Cada FIO come√ßa com contexto claro do que est√° acontecendo.
   - [ ] Fios bem separados por tema/tempo/participantes/tom.
   - [ ] Cada frase substantiva termina com (Nick) ou (quatro d√≠gitos).
   - [ ] Todos os links aparecem no ponto exato em que foram citados.
   - [ ] Subentendidos e tens√µes foram tornados expl√≠citos.
   - [ ] Sem inventar nicks; sem inventar fatos; sem mover links.
   - [ ] Voz √© "n√≥s" narrando nosso pr√≥prio dia, n√£o an√°lise externa.
   - [ ] Lacunas no transcrito (se houver) s√£o explicitadas com honestidade.
"""
    return [types.Part.from_text(text=system_text.strip())]


def ensure_directories(config: PipelineConfig) -> None:
    """Ensure required directories exist."""

    config.newsletters_dir.mkdir(parents=True, exist_ok=True)
    config.zips_dir.mkdir(parents=True, exist_ok=True)


def select_recent_archives(
    archives: Sequence[tuple[date, Path]], *, days: int
) -> list[tuple[date, Path]]:
    """Select the most recent archives respecting *days*."""

    if days <= 0:
        raise ValueError("days must be positive")
    return list(archives[-days:]) if len(archives) >= days else list(archives)


def create_client(api_key: str | None = None) -> genai.Client:
    """Instantiate the Gemini client."""

    _require_google_dependency()

    key = api_key or os.environ.get("GEMINI_API_KEY")
    if not key:
        raise RuntimeError("Defina GEMINI_API_KEY no ambiente.")
    return genai.Client(api_key=key)


def generate_newsletter(
    config: PipelineConfig,
    *,
    days: int = 2,
    client: genai.Client | None = None,
) -> PipelineResult:
    """Execute the pipeline and return the resulting metadata."""

    _require_google_dependency()

    ensure_directories(config)

    archives = list_zip_days(config.zips_dir)
    if not archives:
        raise FileNotFoundError(f"Nenhum .zip encontrado em {config.zips_dir.resolve()}")

    selected_archives = select_recent_archives(archives, days=days)
    transcripts: list[tuple[date, str]] = []
    for archive_date, archive_path in selected_archives:
        transcripts.append((archive_date, read_zip_texts(archive_path)))

    today = max(archive_date for archive_date, _ in transcripts)
    previous_path, previous_content = load_previous_newsletter(config.newsletters_dir, today)

    insert_input = build_llm_input(
        group_name=config.group_name,
        timezone=config.timezone,
        transcripts=transcripts,
        previous_newsletter=previous_content,
    )

    llm_client = client or create_client()
    contents = [
        types.Content(
            role="user",
            parts=[types.Part.from_text(text=insert_input)],
        ),
    ]

    generate_content_config = types.GenerateContentConfig(
        thinking_config=types.ThinkingConfig(thinking_budget=-1),
        safety_settings=[
            types.SafetySetting(category="HARM_CATEGORY_HARASSMENT", threshold="BLOCK_NONE"),
            types.SafetySetting(category="HARM_CATEGORY_HATE_SPEECH", threshold="BLOCK_NONE"),
            types.SafetySetting(category="HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold="BLOCK_NONE"),
            types.SafetySetting(category="HARM_CATEGORY_DANGEROUS_CONTENT", threshold="BLOCK_NONE"),
        ],
        system_instruction=build_system_instruction(),
    )

    output_lines: list[str] = []
    for chunk in llm_client.models.generate_content_stream(
        model=config.model,
        contents=contents,
        config=generate_content_config,
    ):
        if chunk.text:
            output_lines.append(chunk.text)

    newsletter_text = "".join(output_lines).strip()
    output_path = config.newsletters_dir / f"{today.isoformat()}.md"
    output_path.write_text(newsletter_text, encoding="utf-8")

    return PipelineResult(
        output_path=output_path,
        processed_dates=[archive_date for archive_date, _ in transcripts],
        previous_newsletter_path=previous_path,
        previous_newsletter_found=previous_content is not None,
    )


__all__ = [
    "PipelineResult",
    "create_client",
    "generate_newsletter",
]
