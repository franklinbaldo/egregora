"""
Golden-fixture test that exercises the WhatsApp pipeline through the new
Pydantic-AI writer backend.

Rather than replaying previously recorded Gemini HTTP traffic, we stub the
`GoogleModel` with `pydantic_ai.models.test.TestModel`, which deterministically
calls the writer tools and returns structured output. This keeps the test fast,
deterministic, and completely offline while still validating that the Pydantic
agent orchestrates file generation end-to-end.
"""

from __future__ import annotations

from pathlib import Path

import pytest
from pydantic_ai.models.test import TestModel

from egregora.config import resolve_site_paths
from tests.mock_batch_client import create_mock_genai_client


@pytest.mark.vcr
def test_pipeline_with_vcr_fixtures(
    whatsapp_fixture,
    tmp_path: Path,
    monkeypatch: pytest.MonkeyPatch,
):
    """
    Run the full pipeline using the Pydantic-AI writer agent and deterministic
    TestModel responses.

    The VCR mark remains to ensure compatibility with the existing fixture
    configuration, but no external HTTP traffic is generated.
    """
    from egregora.orchestration.pipeline import process_whatsapp_export  # noqa: PLC0415

    output_dir = tmp_path / "site"
    output_dir.mkdir()

    # Create mkdocs.yml for site structure
    mkdocs_yml = output_dir / "mkdocs.yml"
    mkdocs_yml.write_text("site_name: Test Site\ndocs_dir: docs\n", encoding="utf-8")

    docs_dir = output_dir / "docs"
    docs_dir.mkdir()

    # Force the writer to use the Pydantic backend with deterministic tooling.
    monkeypatch.setenv("EGREGORA_LLM_BACKEND", "pydantic")

    class GoldenTestModel(TestModel):
        """TestModel variant with scripted tool arguments for deterministic output."""

        def __init__(self, *, period_date: str):
            self._period_date = period_date
            super().__init__(
                call_tools=["write_post_tool", "write_profile_tool"],
                custom_output_args={
                    "summary": "Golden fixtures generated",
                    "notes": "Deterministic TestModel",
                },
                seed=7,
            )

        def gen_tool_args(self, tool_def):  # type: ignore[override]
            if tool_def.name == "write_post_tool":
                return {
                    "metadata": {
                        "title": "Deterministic Insights",
                        "slug": "deterministic-insights",
                        "date": self._period_date,
                        "tags": ["deterministic", "test"],
                        "authors": ["ca71a986"],
                        "summary": "Synthetic summary generated for golden fixture validation.",
                    },
                    "content": (
                        "# Deterministic Post\n\n"
                        "This content is emitted by GoldenTestModel to keep the pipeline test stable."
                    ),
                }
            if tool_def.name == "write_profile_tool":
                return {
                    "author_uuid": "ca71a986",
                    "content": (
                        "Profile content generated by GoldenTestModel "
                        "to ensure the writer records profile updates."
                    ),
                }
            return super().gen_tool_args(tool_def)

    def _make_test_model(model_name: str) -> TestModel:
        # Period date is derived from the WhatsApp export metadata.
        return GoldenTestModel(period_date=whatsapp_fixture.export_date.isoformat())

    monkeypatch.setattr(
        "egregora.generation.writer.pydantic_agent.GoogleModel",
        _make_test_model,
    )

    client = create_mock_genai_client()

    # Run the pipeline - enrichment remains disabled because we do not stub binary uploads here.
    process_whatsapp_export(
        zip_path=whatsapp_fixture.zip_path,
        output_dir=output_dir,
        period="day",
        enable_enrichment=False,  # VCR limitation: binary uploads cause serialization errors
        retrieval_mode="exact",  # Exact mode avoids VSS extension dependency (see module docstring)
        client=client,
    )

    # Verify that the basic output structure was created
    site_paths = resolve_site_paths(output_dir)
    posts_dir = site_paths.posts_dir
    assert posts_dir.exists(), "Posts directory should be created"

    profiles_dir = site_paths.profiles_dir
    assert profiles_dir.exists(), "Profiles directory should be created"

    # A more specific check to ensure content is being generated
    # This depends on the content of the VCR cassettes
    # For now, we'll just check that some markdown files were created
    md_files = list(posts_dir.glob("*.md"))
    assert len(md_files) > 0, "At least one post markdown file should be created"
