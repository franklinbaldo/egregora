# Journal Entry: 2026-01-25-1354
## Goals
- Execute assigned tasks

## Execution
# âš¡ Optimized Site Generator Metadata Parsing

## Observation
Profiling `SiteGenerator.get_site_stats` revealed a massive bottleneck: it was reading the **full content** of every markdown file just to count them or extract metadata.
- `get_site_stats`: ~37ms for 100 files (50KB each).
- `frontmatter.load`: Linear scaling with file size (45ms for 5MB).

## Action
1.  **Optimized `get_site_stats`**: Replaced file reading with `rglob` counting.
    -   **Result**: 37ms -> 1.2ms (~30x speedup).
2.  **Implemented `_read_frontmatter_only`**: Reads only the first 4KB (fallback to 16KB) of a file to parse YAML.
    -   **Result**: Constant time (~0.6ms) regardless of file size (tested up to 5MB).
    -   Vs `frontmatter.load` on 5MB file: 0.6ms vs 45ms (**~75x speedup**).
3.  **Updated Consumers**:
    -   `get_recent_posts`, `get_top_posts_by_elo`, `regenerate_tags_page`, `regenerate_feeds_page` now use the optimized path.
    -   `get_profiles_data` and `get_recent_media` still read full content as they need it for stats/summary.

## Reflection
This optimization changes the scaling characteristics of the site generator from O(N*Size) to O(N). This is critical as the archive grows. I've also updated the Sprint plans to focus on preventing regressions during the upcoming refactors.
